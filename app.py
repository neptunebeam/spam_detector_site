import os
from typing import Tuple

import numpy as np
import pandas as pd
import streamlit as st
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split

# ---------------- –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ ----------------

st.set_page_config(
    page_title="–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞—Ñ–∏–∫–∞, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ –ø—Ä–æ–¥–∞–∂",
    page_icon="üìà",
    layout="wide",
)

st.title("üìà –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞—Ñ–∏–∫–∞, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ –ø—Ä–æ–¥–∞–∂")
st.caption("–ì–æ—Ç–æ–≤—ã–π —É—á–µ–±–Ω—ã–π —Å–∞–π—Ç-–ø—Ä–æ–µ–∫—Ç –Ω–∞ Python + Streamlit + scikit-learn")

st.markdown(
    """
–≠—Ç–æ—Ç —Å–∞–π—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª **–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤**:

1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **–≥–æ—Ç–æ–≤–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö**
2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –º–µ—Å—è—Ü, –ª–∞–≥–∏)
3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ `RandomForestRegressor`
4. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (MAE, RMSE)
5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ –±—É–¥—É—â–µ–µ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

–ü—Ä–æ–µ–∫—Ç –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ —Ä–∞–±–æ—Ç—É –ø–æ —Ç–µ–º–µ  
**¬´–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞—Ñ–∏–∫–∞ / —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã / –ø—Ä–æ–¥–∞–∂ —Å –ø–æ–º–æ—â—å—é –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è¬ª**.
"""
)

# ---------------- –§–£–ù–ö–¶–ò–ò ----------------


@st.cache_data
def load_csv(file) -> pd.DataFrame:
    return pd.read_csv(file)


@st.cache_data
def load_example_data() -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ sample_data.csv, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å.
    –ò–Ω–∞—á–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ "–ø—Ä–æ–¥–∞–∂".
    """
    path = "sample_data.csv"
    if os.path.exists(path):
        return pd.read_csv(path)

    dates = pd.date_range("2024-01-01", periods=180)
    rng = np.random.default_rng(42)

    # –±–∞–∑–æ–≤—ã–π —Ç—Ä–µ–Ω–¥ + —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å + —à—É–º
    trend = np.linspace(100, 140, len(dates))
    season = 10 * np.sin(np.linspace(0, 6 * np.pi, len(dates)))
    noise = rng.normal(0, 5, len(dates))

    sales = trend + season + noise
    return pd.DataFrame({"date": dates, "value": np.round(sales, 2)})


def build_feature_table(
    df: pd.DataFrame,
    date_col: str,
    target_col: str,
    add_lags: bool = True,
) -> pd.DataFrame:
    data = df.copy()
    data[date_col] = pd.to_datetime(data[date_col])
    data = data.sort_values(date_col)

    # –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    data["dayofweek"] = data[date_col].dt.dayofweek
    data["month"] = data[date_col].dt.month
    data["day"] = data[date_col].dt.day

    # –ª–∞–≥–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    if add_lags:
        data["lag_1"] = data[target_col].shift(1)
        data["lag_7"] = data[target_col].shift(7)

    data = data.dropna()
    return data


def split_train_test(
    data: pd.DataFrame,
    target_col: str,
    test_size: float = 0.2,
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    feature_cols = [c for c in data.columns if c not in [target_col]]
    # –∏—Å–∫–ª—é—á–∞–µ–º —Å–∞–º—É –¥–∞—Ç—É, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    feature_cols = [c for c in feature_cols if "date" not in c.lower()]

    X = data[feature_cols]
    y = data[target_col]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, shuffle=False
    )
    return X_train, X_test, y_train, y_test


def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> RandomForestRegressor:
    model = RandomForestRegressor(
        n_estimators=200,
        max_depth=8,
        random_state=42,
        n_jobs=-1,
    )
    model.fit(X_train, y_train)
    return model


def evaluate_model(
    model: RandomForestRegressor,
    X_test: pd.DataFrame,
    y_test: pd.Series,
):
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    return mae, rmse, y_pred


def make_forecast(
    model: RandomForestRegressor,
    history: pd.DataFrame,
    date_col: str,
    target_col: str,
    horizon: int,
) -> pd.DataFrame:
    df = history.copy()
    df[date_col] = pd.to_datetime(df[date_col])
    df = df.sort_values(date_col)

    last_date = df[date_col].max()
    future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=horizon)

    rows = []
    for dt in future_dates:
        rows.append(
            {
                date_col: dt,
                "dayofweek": dt.dayofweek,
                "month": dt.month,
                "day": dt.day,
            }
        )
    future = pd.DataFrame(rows)

    full = pd.concat([df[[date_col, target_col]], future[[date_col]]], ignore_index=True)
    full = full.sort_values(date_col).reset_index(drop=True)

    # –ø—Ä–æ—Ç—è–≥–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    full[target_col] = full[target_col].ffill()

    full["lag_1"] = full[target_col].shift(1)
    full["lag_7"] = full[target_col].shift(7)

    future = future.merge(full[[date_col, "lag_1", "lag_7"]], on=date_col, how="left")

    future["lag_1"] = future["lag_1"].ffill()
    future["lag_7"] = future["lag_7"].ffill()

    feature_cols = [c for c in future.columns if c not in [date_col, target_col]]
    X_future = future[feature_cols]

    future[target_col + "_pred"] = model.predict(X_future)

    return future[[date_col, target_col + "_pred"]]


# ---------------- UI: –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ----------------

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    scenario = st.selectbox(
        "–¢–∏–ø —Å—Ü–µ–Ω–∞—Ä–∏—è",
        [
            "–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂",
            "–ü—Ä–æ–≥–Ω–æ–∑ —Ç—Ä–∞—Ñ–∏–∫–∞ (–ø–æ—Å–µ—â–µ–Ω–∏—è / –∑–∞–ø—Ä–æ—Å—ã)",
            "–ü—Ä–æ–≥–Ω–æ–∑ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã",
        ],
    )
    horizon = st.slider("–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ (–¥–Ω–µ–π)", 7, 60, 21)
    st.markdown(
        """
        **–ü–æ–¥—Å–∫–∞–∑–∫–∞:**
        1. –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö.
        2. –ü–æ—Ç–æ–º –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–π CSV.
        """
    )

# ---------------- –ë–õ–û–ö –î–ê–ù–ù–´–• ----------------

st.subheader("1. –î–∞–Ω–Ω—ã–µ")

tab_example, tab_upload = st.tabs(["üìò –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö", "üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π CSV"])

with tab_example:
    example_df = load_example_data()
    st.write("–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è):")
    st.dataframe(example_df.head())

    csv_bytes = example_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (sample_data.csv)",
        data=csv_bytes,
        file_name="sample_data.csv",
        mime="text/csv",
    )

with tab_upload:
    uploaded = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π –∏ —á–∏—Å–ª–æ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞)",
        type=["csv"],
    )

use_example_only = uploaded is None
if use_example_only:
    df_raw = example_df.copy()
    st.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö.")
else:
    df_raw = load_csv(uploaded)
    st.success("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª.")

st.write("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
st.dataframe(df_raw.head())

if df_raw.shape[1] < 2:
    st.error("–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –∫–æ–ª–æ–Ω–∫–∏: –¥–∞—Ç–∞ –∏ —á–∏—Å–ª–æ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å.")
    st.stop()

# ---------------- –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ----------------

st.subheader("2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

date_col = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π", options=df_raw.columns, index=0)

# —Ä–∞–∑—É–º–Ω—ã–π –≤—ã–±–æ—Ä —Ü–µ–ª–µ–≤–æ–π –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
target_default = 1
for i, col in enumerate(df_raw.columns):
    if col.lower() in ["value", "sales", "traffic", "temperature", "target"]:
        target_default = i
        break

target_col = st.selectbox(
    "–¶–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ (—á—Ç–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º)", options=df_raw.columns, index=target_default
)

if date_col == target_col:
    st.error("–ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π –∏ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞–∑–Ω—ã–º–∏.")
    st.stop()

try:
    data_features = build_feature_table(df_raw, date_col, target_col)
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
    st.stop()

if len(data_features) < 30:
    st.warning("–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö (< 30 —Å—Ç—Ä–æ–∫) ‚Äî –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º.")

st.write("–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ (—á–∞—Å—Ç—å):")
st.dataframe(data_features.head())

# ---------------- –ú–û–î–ï–õ–¨ ----------------

st.subheader("3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–æ")

X_train, X_test, y_train, y_test = split_train_test(data_features, target_col)
model = train_model(X_train, y_train)
mae, rmse, y_pred_test = evaluate_model(model, X_test, y_test)

c1, c2, c3 = st.columns(3)
with c1:
    st.metric("MAE", f"{mae:,.3f}")
with c2:
    st.metric("RMSE", f"{rmse:,.3f}")
with c3:
    st.metric("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏", len(X_test))

# ---------------- –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ----------------

st.subheader("4. –ò—Å—Ç–æ—Ä–∏—è –∏ –ø—Ä–æ–≥–Ω–æ–∑")

history_chart = df_raw[[date_col, target_col]].copy()
history_chart[date_col] = pd.to_datetime(history_chart[date_col])
history_chart = history_chart.sort_values(date_col)

st.markdown("**–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:**")
st.line_chart(history_chart.set_index(date_col)[target_col], height=250)

forecast_df = make_forecast(
    model=model,
    history=df_raw[[date_col, target_col]],
    date_col=date_col,
    target_col=target_col,
    horizon=horizon,
)

st.markdown(f"**–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ {horizon} –¥–Ω–µ–π:**")
st.dataframe(forecast_df)

st.line_chart(
    forecast_df.set_index(date_col)[f"{target_col}_pred"],
    height=250,
)

# ---------------- –û–ü–ò–°–ê–ù–ò–ï –î–õ–Ø –û–¢–ß–ï–¢–ê ----------------

st.markdown(
    """
---

### üßæ –ö–∞–∫ –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –Ω–∞ –∑–∞—â–∏—Ç–µ

- **–¶–µ–ª—å —Ä–∞–±–æ—Ç—ã:** —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤  
  (–ø—Ä–æ–¥–∞–∂–∏, —Ç—Ä–∞—Ñ–∏–∫, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞) —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
- **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:** Python, –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `pandas`, `numpy`, `scikit-learn`, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ `Streamlit`.
- **–ú–æ–¥–µ–ª—å:** –∞–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å `RandomForestRegressor` –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.
- **–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:** —Ç–∞–±–ª–∏—Ü–∞ (CSV) —Å –¥–≤—É–º—è –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏:
  - –¥–∞—Ç–∞ (`date`)
  - —á–∏—Å–ª–æ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å (–ø—Ä–æ–¥–∞–∂–∏ / —Ç—Ä–∞—Ñ–∏–∫ / —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞).
- **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, —Å–∏—Å—Ç–µ–º–∞:
  1. —Å—Ç—Ä–æ–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ + –ª–∞–≥–∏),
  2. –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏,
  3. –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ (MAE, RMSE),
  4. —Å—Ç—Ä–æ–∏—Ç –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –≤ –¥–Ω—è—Ö.

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –≥–æ—Ç–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è ML
–∫ –∑–∞–¥–∞—á–∞–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –±–∏–∑–Ω–µ—Å–µ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ.
"""
)
